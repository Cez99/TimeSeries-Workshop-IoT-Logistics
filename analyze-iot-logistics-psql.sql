-- ============================================================================
-- IoT Logistics Fleet Telemetry (TimescaleDB + PostGIS)
-- ============================================================================
-- This workshop demonstrates time-series + geospatial analytics for tracking a
-- fleet of trucks moving cargo between cities.
--
-- Dataset (manageable):
--   - 1,000 trucks
--   - 7 days of history
--   - a reading every 5 seconds per truck
--
-- Tip: to scale down further, change '7 days' or '5 second' in the INSERT below.
-- ============================================================================

-- ============================================================================
-- Enable Extensions
-- ============================================================================
CREATE EXTENSION IF NOT EXISTS timescaledb;
CREATE EXTENSION IF NOT EXISTS postgis;

-- ============================================================================
-- Drop existing objects (safe for workshop)
-- ============================================================================
DROP MATERIALIZED VIEW IF EXISTS daily_truck_summary CASCADE;

DROP TABLE IF EXISTS truck_telemetry CASCADE;
DROP TABLE IF EXISTS trucks CASCADE;
DROP TABLE IF EXISTS cities CASCADE;

DROP FUNCTION IF EXISTS truck_route_point(INT, TIMESTAMPTZ, TIMESTAMPTZ);

-- ============================================================================
-- Create Reference Tables
-- ============================================================================
CREATE TABLE cities (
   id       INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
   name     TEXT NOT NULL,
   location GEOGRAPHY(POINT, 4326) NOT NULL
);

INSERT INTO cities (name, location) VALUES
  ('Vancouver',     ST_SetSRID(ST_MakePoint(-123.1207, 49.2827), 4326)::geography),
  ('Seattle',       ST_SetSRID(ST_MakePoint(-122.3321, 47.6062), 4326)::geography),
  ('Portland',      ST_SetSRID(ST_MakePoint(-122.6765, 45.5231), 4326)::geography),
  ('San Francisco', ST_SetSRID(ST_MakePoint(-122.4194, 37.7749), 4326)::geography),
  ('Los Angeles',   ST_SetSRID(ST_MakePoint(-118.2437, 34.0522), 4326)::geography),
  ('Denver',        ST_SetSRID(ST_MakePoint(-104.9903, 39.7392), 4326)::geography),
  ('Chicago',       ST_SetSRID(ST_MakePoint(-87.6298, 41.8781), 4326)::geography),
  ('Dallas',        ST_SetSRID(ST_MakePoint(-96.7970, 32.7767), 4326)::geography);

CREATE TABLE trucks (
   id             INTEGER PRIMARY KEY,
   origin_city_id INTEGER NOT NULL REFERENCES cities(id),
   dest_city_id   INTEGER NOT NULL REFERENCES cities(id),
   seed           DOUBLE PRECISION NOT NULL
);

-- 1,000 trucks with deterministic origin/destination assignment
INSERT INTO trucks (id, origin_city_id, dest_city_id, seed)
SELECT
  t AS id,
  ((t % (SELECT count(*) FROM cities)) + 1) AS origin_city_id,
  (((t + 3) % (SELECT count(*) FROM cities)) + 1) AS dest_city_id,
  (('x'||substr(md5(t::text),1,8))::bit(32)::int / 2147483647.0) AS seed
FROM generate_series(1, 1000) AS g(t);

-- ============================================================================
-- Create Telemetry Hypertable (telemetry + geolocation)
-- ============================================================================
CREATE TABLE truck_telemetry (
   time           TIMESTAMPTZ NOT NULL,
   truck_id       INTEGER NOT NULL REFERENCES trucks(id),

   -- GPS location as geography (meters-based distance and ST_DWithin)
   location       GEOGRAPHY(POINT, 4326) NOT NULL,

   -- Telemetry
   speed_kph      DOUBLE PRECISION NOT NULL,
   heading_deg    DOUBLE PRECISION NOT NULL,
   engine_temp_c  DOUBLE PRECISION NOT NULL,
   fuel_pct       DOUBLE PRECISION NOT NULL,
   cargo_kg       DOUBLE PRECISION NOT NULL,

   -- Route context (denormalized for easy analytics)
   origin_city_id INTEGER NOT NULL,
   dest_city_id   INTEGER NOT NULL
);

SELECT create_hypertable('truck_telemetry', 'time');

CREATE INDEX truck_telemetry_truck_time_idx ON truck_telemetry (truck_id, time DESC);
CREATE INDEX truck_telemetry_location_gist ON truck_telemetry USING GIST (location);

-- ============================================================================
-- Movement model: create a synthetic "route point" per truck + timestamp
-- ============================================================================
-- Movement is approximated as repeated trips from origin -> destination,
-- looping forever. Trip duration varies per truck (deterministically).
CREATE OR REPLACE FUNCTION truck_route_point(
  p_truck_id INT,
  p_time TIMESTAMPTZ,
  p_start_time TIMESTAMPTZ
) RETURNS GEOGRAPHY(POINT,4326)
LANGUAGE SQL
STABLE
AS $$
WITH t AS (
  SELECT
    tr.seed,
    c1.location AS origin,
    c2.location AS dest
  FROM trucks tr
  JOIN cities c1 ON c1.id = tr.origin_city_id
  JOIN cities c2 ON c2.id = tr.dest_city_id
  WHERE tr.id = p_truck_id
),
params AS (
  SELECT
    -- trip duration: 4h..16h
    (14400 + (t.seed * 43200))::DOUBLE PRECISION AS trip_seconds
  FROM t
),
progress AS (
  SELECT
    mod(extract(epoch from (p_time - p_start_time)), params.trip_seconds) / params.trip_seconds AS frac
  FROM params
),
line AS (
  SELECT
    ST_MakeLine(t.origin::geometry, t.dest::geometry) AS geom_line,
    progress.frac AS frac,
    t.seed AS seed
  FROM t, progress
),
pt AS (
  SELECT
    ST_LineInterpolatePoint(geom_line, frac) AS base_pt,
    seed
  FROM line
),
jitter AS (
  SELECT
    -- small jitter to reduce overplotting (roughly tens of meters)
    ST_Translate(
      base_pt,
      (seed - 0.5) * 0.0005,
      ((seed * 1.7) - 0.5) * 0.0005
    ) AS geom_pt
  FROM pt
)
SELECT ST_SetSRID(geom_pt,4326)::geography
FROM jitter;
$$;

-- ============================================================================
-- Generate a simulated fleet telemetry dataset
-- ============================================================================
-- Change '7 days' or '5 second' to generate different volumes.
INSERT INTO truck_telemetry (
   time, truck_id, location,
   speed_kph, heading_deg, engine_temp_c, fuel_pct, cargo_kg,
   origin_city_id, dest_city_id
)
SELECT
   g.time,
   tr.id AS truck_id,
   truck_route_point(tr.id, g.time, now() - interval '7 days') AS location,

   -- Telemetry ranges
   40 + (70 * random()) + (tr.seed * 5) AS speed_kph,
   (random() * 360.0) AS heading_deg,
   70 + (random() * 40.0) AS engine_temp_c,
   GREATEST(5.0, 100.0 - (random() * 95.0)) AS fuel_pct,
   (random() * 20000.0) AS cargo_kg,

   tr.origin_city_id,
   tr.dest_city_id
FROM generate_series(now() - interval '7 days', now(), interval '5 second') AS g(time),
     trucks tr;

ANALYZE truck_telemetry;

-- ============================================================================
-- Verify the simulated telemetry dataset
-- ============================================================================
SELECT * FROM truck_telemetry ORDER BY time DESC LIMIT 10;

-- ============================================================================
-- Verify fleet metadata and routes (trucks + cities)
-- ============================================================================
SELECT
  tr.id AS truck_id,
  o.name AS origin_city,
  d.name AS dest_city
FROM trucks tr
JOIN cities o ON o.id = tr.origin_city_id
JOIN cities d ON d.id = tr.dest_city_id
ORDER BY tr.id
LIMIT 25;

-- ============================================================================
-- Examine Hypertable Partitions (chunks)
-- ============================================================================
SELECT
   chunk_name,
   range_start,
   range_end,
   is_compressed
FROM timescaledb_information.chunks
WHERE hypertable_name = 'truck_telemetry'
ORDER BY range_start;

-- ============================================================================
-- Sample Fleet Analytics Queries
-- ============================================================================
-- ### Trucks with high engine temperature in the past hour
SELECT
   time,
   truck_id,
   engine_temp_c,
   speed_kph,
   fuel_pct
FROM truck_telemetry
WHERE time >= NOW() - INTERVAL '1 hour'
  AND engine_temp_c > 105
ORDER BY time DESC
LIMIT 200;

-- ### Average speed by 5-minute windows (fleet-level)
SELECT
   time_bucket('5 minutes', time) AS bucket,
   ROUND(AVG(speed_kph)::numeric, 2) AS avg_speed_kph,
   ROUND(MAX(speed_kph)::numeric, 2) AS max_speed_kph,
   COUNT(*) AS readings
FROM truck_telemetry
WHERE time >= NOW() - INTERVAL '6 hours'
GROUP BY bucket
ORDER BY bucket DESC
LIMIT 72;

-- ============================================================================
-- JOIN Hypertable and Regular Tables
-- ============================================================================
-- While organized differently internally, hypertables are fully-featured
-- PostgreSQL tables. You can join them with other tables.
SELECT
  t.time,
  t.truck_id,
  o.name AS origin_city,
  d.name AS dest_city,
  t.speed_kph,
  t.fuel_pct
FROM truck_telemetry t
JOIN trucks tr ON tr.id = t.truck_id
JOIN cities o ON o.id = tr.origin_city_id
JOIN cities d ON d.id = tr.dest_city_id
WHERE t.time >= NOW() - INTERVAL '30 minutes'
ORDER BY t.time DESC
LIMIT 200;

-- ============================================================================
-- Daily Truck Summary (baseline on hypertable)
-- ============================================================================
-- Remember the time it took to run the query. Later we will compare the performance
-- of the same query on compressed data and preaggregated data in a continuous aggregate.
WITH daily AS (
  SELECT
    time_bucket('1 day', time) AS day,
    truck_id,
    time,
    location,
    speed_kph,
    fuel_pct
  FROM truck_telemetry
  WHERE time >= NOW() - INTERVAL '7 days'
),
segments AS (
  SELECT
    day,
    truck_id,
    time,
    speed_kph,
    fuel_pct,
    ST_Distance(
      location,
      LAG(location) OVER (PARTITION BY day, truck_id ORDER BY time)
    ) AS meters
  FROM daily
)
SELECT
  day,
  truck_id,
  ROUND(AVG(speed_kph)::numeric, 2) AS avg_speed_kph,
  ROUND(MIN(fuel_pct)::numeric, 2)  AS min_fuel_pct,
  ROUND(SUM(COALESCE(meters,0))/1000.0::numeric, 2) AS km_traveled,
  COUNT(*) AS readings
FROM segments
GROUP BY day, truck_id
ORDER BY day DESC, km_traveled DESC
LIMIT 50;

-- ============================================================================
-- Geospatial Queries (PostGIS)
-- ============================================================================
-- ### Geofence query: trucks inside a polygon during a time window
WITH fence AS (
  SELECT ST_GeomFromText(
    'POLYGON((-122.36 47.58,-122.36 47.66,-122.28 47.66,-122.28 47.58,-122.36 47.58))',
    4326
  )::geography AS poly
)
SELECT
  time,
  truck_id
FROM truck_telemetry, fence
WHERE time >= NOW() - INTERVAL '30 minutes'
  AND ST_Contains(fence.poly::geometry, truck_telemetry.location::geometry)
ORDER BY time DESC
LIMIT 200;

-- ### Proximity query: trucks within 25km of Vancouver in the last hour
WITH depot AS (
  SELECT location AS city_loc
  FROM cities
  WHERE name = 'Vancouver'
)
SELECT
  t.time,
  t.truck_id,
  ROUND(ST_Distance(t.location, depot.city_loc)/1000.0::numeric, 2) AS km_from_vancouver
FROM truck_telemetry t, depot
WHERE t.time >= NOW() - INTERVAL '1 hour'
  AND ST_DWithin(t.location, depot.city_loc, 25000)
ORDER BY t.time DESC
LIMIT 200;

-- ### Distance from origin city (latest point)
WITH origin AS (
  SELECT tr.id AS truck_id, c.location AS origin_loc
  FROM trucks tr
  JOIN cities c ON c.id = tr.origin_city_id
),
latest AS (
  SELECT DISTINCT ON (truck_id)
    truck_id, time, location
  FROM truck_telemetry
  ORDER BY truck_id, time DESC
)
SELECT
  latest.truck_id,
  latest.time,
  ROUND(ST_Distance(latest.location, origin.origin_loc)/1000.0::numeric, 2) AS km_from_origin
FROM latest
JOIN origin ON origin.truck_id = latest.truck_id
ORDER BY km_from_origin DESC
LIMIT 50;

-- ============================================================================
-- Enable Columnarstore (Compression)
-- ============================================================================
-- Enabling a columnstore for the table by itself does not compress the data.
-- You can either manually compress hypertable chunks or create a policy to
-- automatically compress chunks.
--
-- NOTE:
-- For a 7-day dataset, you may want an aggressive policy (after 1 day).
-- In real production, you would likely compress after a longer interval.
SELECT compress_chunk(c, true) FROM show_chunks('truck_telemetry') c;
CALL add_columnstore_policy('truck_telemetry', after => INTERVAL '1 day');

-- ============================================================================
-- Storage Saved by Compression
-- ============================================================================
SELECT
   pg_size_pretty(before_compression_total_bytes) AS before,
   pg_size_pretty(after_compression_total_bytes) AS after,
   ROUND((1 - after_compression_total_bytes::NUMERIC /
          before_compression_total_bytes) * 100, 2) AS compression_ratio_percent
FROM hypertable_compression_stats('truck_telemetry');

-- ============================================================================
-- Daily Truck Summary (same query on compressed hypertable)
-- ============================================================================
WITH daily AS (
  SELECT
    time_bucket('1 day', time) AS day,
    truck_id,
    time,
    location,
    speed_kph,
    fuel_pct
  FROM truck_telemetry
  WHERE time >= NOW() - INTERVAL '7 days'
),
segments AS (
  SELECT
    day,
    truck_id,
    time,
    speed_kph,
    fuel_pct,
    ST_Distance(
      location,
      LAG(location) OVER (PARTITION BY day, truck_id ORDER BY time)
    ) AS meters
  FROM daily
)
SELECT
  day,
  truck_id,
  ROUND(AVG(speed_kph)::numeric, 2) AS avg_speed_kph,
  ROUND(MIN(fuel_pct)::numeric, 2)  AS min_fuel_pct,
  ROUND(SUM(COALESCE(meters,0))/1000.0::numeric, 2) AS km_traveled,
  COUNT(*) AS readings
FROM segments
GROUP BY day, truck_id
ORDER BY day DESC, km_traveled DESC
LIMIT 50;

-- ============================================================================
-- Create Continuous Aggregate for Daily Truck Summary
-- ============================================================================
-- Continuous aggregates pre-aggregate hypertable data into a materialized view.
-- Querying a continuous aggregate is typically much faster than scanning raw data.
CREATE MATERIALIZED VIEW daily_truck_summary
WITH (
  timescaledb.continuous,
  timescaledb.materialized_only = false
) AS
WITH daily AS (
  SELECT
    time_bucket('1 day', time) AS day,
    truck_id,
    time,
    location,
    speed_kph,
    fuel_pct
  FROM truck_telemetry
),
segments AS (
  SELECT
    day,
    truck_id,
    time,
    speed_kph,
    fuel_pct,
    ST_Distance(
      location,
      LAG(location) OVER (PARTITION BY day, truck_id ORDER BY time)
    ) AS meters
  FROM daily
)
SELECT
  day,
  truck_id,
  AVG(speed_kph) AS avg_speed_kph,
  MIN(fuel_pct)  AS min_fuel_pct,
  SUM(COALESCE(meters,0))/1000.0 AS km_traveled,
  COUNT(*) AS readings
FROM segments
GROUP BY day, truck_id;

-- ============================================================================
-- Create Continuous Aggregate Policy
-- ============================================================================
SELECT add_continuous_aggregate_policy(
  'daily_truck_summary',
  start_offset => INTERVAL '7 days',
  end_offset   => INTERVAL '1 day',
  schedule_interval => INTERVAL '1 day'
);

-- ============================================================================
-- Query Daily Truck Summary Continuous Aggregate
-- ============================================================================
SELECT *
FROM daily_truck_summary
WHERE day >= NOW() - INTERVAL '7 days'
ORDER BY day DESC, km_traveled DESC
LIMIT 50;

-- ============================================================================
-- Real Time Continuous Aggregates
-- ============================================================================
-- Insert a new row and verify it appears in raw telemetry and (real-time) cagg.
-- Note: real-time behavior depends on the continuous aggregate settings and version.
INSERT INTO truck_telemetry (
  time, truck_id, location,
  speed_kph, heading_deg, engine_temp_c, fuel_pct, cargo_kg,
  origin_city_id, dest_city_id
)
SELECT
  NOW(),
  1,
  truck_route_point(1, NOW(), NOW() - interval '7 days'),
  72.0,
  180.0,
  92.0,
  55.0,
  12000.0,
  origin_city_id,
  dest_city_id
FROM trucks
WHERE id = 1;

-- Verify the insert
SELECT *
FROM truck_telemetry
WHERE time >= NOW() - INTERVAL '5 minutes'
  AND truck_id = 1
ORDER BY time DESC
LIMIT 20;

-- Verify real-time update in continuous aggregate (should reflect latest day)
SELECT *
FROM daily_truck_summary
WHERE day >= NOW() - INTERVAL '2 days'
  AND truck_id = 1
ORDER BY day DESC
LIMIT 5;

-- ============================================================================
-- Add Data Retention Policy (optional)
-- ============================================================================
-- Drop raw telemetry older than 30 days (example)
-- SELECT add_retention_policy('truck_telemetry', INTERVAL '30 days');

